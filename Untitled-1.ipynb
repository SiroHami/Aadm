{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformTwice:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, input):\n",
    "        output1 = self.transform(input)\n",
    "        output2 = self.transform(input)\n",
    "        return output1, output2\n",
    "\n",
    "\n",
    "class datasets_labeled(datasets):\n",
    "\n",
    "    def __init__(self, root, indexs=None, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        super(datasets_labeled, self).__init__(root, train=train,\n",
    "                 transform=transform, target_transform=target_transform,\n",
    "                 download=download)\n",
    "        if indexs is not None:\n",
    "            self.data = self.data[indexs]\n",
    "            self.targets = np.array(self.targets)[indexs]\n",
    "        self.data = transforms.transpose(transforms.normalize(self.data))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "\n",
    "class datasets_unlabeled(datasets_labeled):\n",
    "\n",
    "    def __init__(self, root, indexs, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        super(datasets_unlabeled, self).__init__(root, indexs, train=train,\n",
    "                 transform=transform, target_transform=target_transform,\n",
    "                 download=download)\n",
    "        self.targets = np.array([-1 for i in range(len(self.targets))])\n",
    "\n",
    "def get_datasets(root, n_labeled, datasets,\n",
    "            transform_train=None, transform_val=None,\n",
    "            download=True):\n",
    "\n",
    "            base_dataset = datasets(root, train=True, download=True)\n",
    "            train_labeled_idxs, train_unlabeled_idxs, val_idxs = train_val_split(base_dataset.targets, int(n_labeled/10))\n",
    "            train_labeled_dataset = datasets_labeled(root, train_labeled_idxs, train=True, transform=transform_train)\n",
    "            train_unlabeled_dataset = datasets_unlabeled(root, train_unlabeled_idxs, train=True, transform=TransformTwice(transform_train))\n",
    "            val_dataset = datasets_labeled(root, val_idxs, train=True, transform=transform_val, download=True)\n",
    "            test_dataset = datasets_labeled(root, train=False, transform=transform_val, download=True)\n",
    "\n",
    "            print (f\"#Labeled: {len(train_labeled_idxs)} #Unlabeled: {len(train_unlabeled_idxs)} #Val: {len(val_idxs)}\")\n",
    "            return train_labeled_dataset, train_unlabeled_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "def train_val_split(labels, n_labeled_per_class):\n",
    "    labels = np.array(labels)\n",
    "    train_labeled_idxs = []\n",
    "    train_unlabeled_idxs = []\n",
    "    val_idxs = []\n",
    "\n",
    "    for i in range(labels):\n",
    "        idxs = np.where(labels == i)[0]\n",
    "        np.random.shuffle(idxs)\n",
    "        train_labeled_idxs.extend(idxs[:n_labeled_per_class])\n",
    "        train_unlabeled_idxs.extend(idxs[n_labeled_per_class:-500])\n",
    "        val_idxs.extend(idxs[-500:])\n",
    "    np.random.shuffle(train_labeled_idxs)\n",
    "    np.random.shuffle(train_unlabeled_idxs)\n",
    "    np.random.shuffle(val_idxs)\n",
    "\n",
    "    return train_labeled_idxs, train_unlabeled_idxs, val_idxs\n",
    "\n",
    "def get_mean_std(datasets):\n",
    "    imgs = [item[0] for item in datasets.trainset] # item[0] and item[1] are image and its label\n",
    "    imgs = torch.stack(imgs, dim=0).numpy()\n",
    "\n",
    "    # calculate mean over each channel (r,g,b)\n",
    "    mean_r = imgs[:,0,:,:].mean()\n",
    "    mean_g = imgs[:,1,:,:].mean()\n",
    "    mean_b = imgs[:,2,:,:].mean()\n",
    "    print(mean_r,mean_g,mean_b)\n",
    "\n",
    "    # calculate std over each channel (r,g,b)\n",
    "    std_r = imgs[:,0,:,:].std()\n",
    "    std_g = imgs[:,1,:,:].std()\n",
    "    std_b = imgs[:,2,:,:].std()\n",
    "    print(std_r,std_g,std_b)\n",
    "\n",
    "    mean = (mean_r, mean_g, mean_b)\n",
    "    std = (std_r, std_g, std_b)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "datasets_mean, datasets_std = get_mean_std(datasets)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
